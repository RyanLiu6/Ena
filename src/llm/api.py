import json
import logging

import ollama

from json.decoder import JSONDecodeError

from src.model import Category, Transaction


class LLM:
    def __init__(self):
        """
        Ensures that the ryanliu6/ena model is always on disk
        """
        ollama.pull("ryanliu6/ena")

    def categorize_transaction(self, transaction: Transaction) -> Category:
        """
        Categorizes a given transaction using LLM via local ollama.

        If the LLM does not return a valid JSON object, then we return the catch-all
        expense (Category.EXPENSE) category.

        Similarly, if the LLM returns a category that is not specified, we will also return
        the same catch-all expense (Category.EXPENSE) category.

        Note: First usage of this function might take a long time, due to ollama needing to
        load the model into memory. If possible, load the model beforehand. By default, ollama
        keeps a model in memory for 5 minutes before unloading.

        Args:
            transaction (Transaction): Transaction to be categorized, assumed to be an expense.

        Returns:
            Category: Category of this Transaction, generated by an LLM
        """
        # result of ollama.generate is a dictionary with a bunch of stuff, we're only interested in response
        llm_result = ollama.generate(model="ryanliu6/ena", prompt=Transaction.note)["response"]

        # LLM response should be in JSON, where keys are category and confidence
        try:
            json_result = json.loads(llm_result)
        except JSONDecodeError:
            return Category.EXPENSE

        # Try to interpolate generated by the LLM
        try:
            llm_category = Category[json_result["category"]]
            logging.info(f"Transaction [{transaction}] has been categorized as {llm_category} with a {json_result['confidence']}% confidence.")
        except KeyError:
            llm_category = Category.EXPENSE

        return llm_category
